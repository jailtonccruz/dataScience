x = 0
x
for (i in 1:10000)
{
y = sample(1:6,1)
y
x = x + y
}
x = x / 10000
x
x = 0
x
for (i in 1:10000)
{
y = sample(1:6,1)
y
x = x + y
}
x = x / 10000
x
d = dminon(3,5,0.5)
d = dbinon(3,5,0.5)
d = dbinom(3,5,0.5)
d = dbinom(3,5,0.5)
d
d = dbinom(3,10,0.5)
d
d = dbinom(3,3,0.5)
d
d = dbinom(3,3,0.5)
d
d = dbinom(3,50,0.5)
d
d = dbinom(3,5000.5)
d
d = dbinom(3,500,0.5)
d
d = dbinom(3,3,0.5)
d
d = dbinom(3,4,0.5)
d
d = dbinom(3,5,0.5)
d
d = dbinom(3,10,0.5)
d
dbinom(7, 12, 0.25)
dbinom(12, 12, 0.25)
dbinom(1,4,0,25)
dbinom(1,4,0.25)
dbinom(4,4,0.25) # prop.de encontra 2 verdes
pbinom(4,4,0.25) # prop.de encontra 1 verde
dbinom(7, 12, 0.25)
dbinom(1,4,0.25) # prop.de encontra 1 verde
pnorm(6,8,2)
pnorm(6,8,2)
pnorm(6,8,2 lower.tail = F)
pnorm(6,8,2,lower.tail = F)
#ou
1 - pnorm(6,8,2)
1 - pnorm(6,8,2)
pnorm(6,8,2) + pnorm(10,8,2, lower.tail = F)
pnorm(10,8,2) - pnorm(8,8,2, lower.tail = False)
# menor que 10 e maior que 8
pnorm(10,8,2) - pnorm(8,8,2, lower.tail = F)
pnorm(10,8,2) - pnorm(8,8,2)
pnorm(10,8,2)
pnorm(8,8,2)
#Gerar um diagrama de normalidade
x = rnorm(100)
x
aleat = rnorm(100)
aleat
aleat = rnorm(100)
aleat
aleat = rnorm(100)
aleat
aleat = rnorm(100)
aleat
qqnorm(aleat)
qqline(aleat)
shapiro.test(aleat)
pt(1.5, 8)
pt(1.5, 8, lower.tail = F)
dim(cars)
head(cars)
dim(cars)
head(cars)
cor(cars)
modelo = lm(speed ~ dist, data=cars)
modelo
plot(modelo)
abline(modelo)
abline(modelo)
abline(modelo)
plot(modelo)
abline(modelo)
modelo = lm(speed ~ dist, data=cars)
modelo
abline(modelo)
modelo = lm(speed ~ dist, data=cars)
modelo
plot(modelo)
Modelo
modelo$coeficiente
modelo$coefficients
modelo$coefficients[1]
modelo$coefficients[2]
modelo$coefficients[1] + modelo$coefficients[2] * 22
modelo
modelo$coefficients[1]
modelo$coefficients[2]
predict(modelo, data.frame (dist = 22))
summary(modelo)
modelo$
modelo$call
modelo$model
modelo$
modelo
modelo$
modelo$residuals
modelo$fitted.values
modelo$residuals
modelo$
modelo$
modelo$effects
dim(cars)
head(cars)
cor(cars)
# Criar um modelo usando a funcao lm (linear model)
modelo = lm(speed ~ dist, data=cars)
modelo
modelo$fitted.values
modelo$residuals
modelo$
modelo
modelo$coefficients
colnames(mtcars)
dim(mtcars)
cor(mtcars[1:4])
cor(mtcars)
cor(mtcars)
modelCars = lm(mpg ~ disp, data=mtcars)
modelCars
summary(modelCars)$r.squared
r2 = summary(modelCars)$r.squared
r2
r2Adj = summary(modelCars)$adj.r.squared
r2Adj
plot(mgp ~ disp, data=mtcars)
plot(mpg ~ disp, data=mtcars)
modelo = lm(speed ~ dist, data=cars)
modelo
plot(modelo)
plot(mpg ~ disp, data=mtcars)
abline(r2Adj)
abline(modelCars)
predict(modelCars)
predict(modelCars, data.frame(disp=200))
ModelCarsRLM = lm(mpg ~ disp + hp + cyl, data=mtcars)
ModelCarsRLM
summary(ModelCarsRLM)$r.squared
summary(ModelCarsRLM)$adj.r.squared
predict(ModelCarsRLM, data.frame(disp= 200, hp = 100, cyl = 4))
plot(ModelCarsRLM)
eleicao = read.csv(file.choose(), sep=';' header='T')
eleicao = read.csv(file.choose(), sep=";", header="T")
dpois(3,lambda=2)
ppois(3,lambda=2)
ppois(3,lambda=2, lower.tail=F)
novela = matrix(c(19,6,43,32),nrow=2, byrow=T)
rownames(novela) = c("Masculino","Feminino")
colnames(novela) = c("Assiste","NaoAssiste")
chisq.test(novela)
View(novaAmostra)
View(novaAmostra)
View(iris_ds)
View(x)
fix(novela)
fix(novela)
fix(novela)
novela = matrix(c(19,6,43,32),nrow=2, byrow=T)
fix(novela)
rownames(novela) = c("Masculino","Feminino")
colnames(novela) = c("Assiste","NaoAssiste")
fix(novela)
fix(tratamento)
tratamento = read.csv(file.choose(), sep=";", header=T)
fix(tratamento)
fix(tratamento)
tratamento = read.csv(file.choose(), sep=";", header=T)
fix(tratamento)
boxplot(tratamento$Horas ~ tratamento$Remedio)
summary(an)
tratamento = read.csv(file.choose(), sep=";", header=T)
tratamento = read.csv(file.choose(), sep=";", header=T)
fix(tratamento)
boxplot(tratamento$Horas ~ tratamento$Remedio)
an =  aov(Horas ~ Remedio, data=tratamento)
install.package("tm")
install.packages("tm")
install.packages("tm")
install.packages("tm")
corpus = VCorpus(DirSource("C:\dataScience\Curso\MineracaoTextos\Dados", encoding = "UTF-8"),readerControl = list(reader=readPlain,language = "por"))
corpus = VCorpus(DirSource("C:\dataScience\Curso\MineracaoTextos\Dados", encoding = "UTF-8"),readerControl = list(reader=readPlain,language = "por"))
corpus = VCorpus(DirSource("C:/dataScience/Curso/MineracaoTextos/Dados", encoding = "UTF-8"),readerControl = list(reader=readPlain,language = "por"))
install.packages("tm")
install.packages("tm", repos="http://R-Forge.R-project.org")
install.packages("tm")
install.packages("C:\Users\jailton\Downloads\tm_0.7-7\tm\R\tm")
install.packages("C:/Users/jailton/Downloads/tm_0.7-7/tm/R/tm")
require(devtools)
install_version("tm", version = "0.7-1", repos = "http://cran.us.r-project.org")
install.packages("tm", repos="http://cran.us.r-project.org")
library(tm)
install.packages("tm")
insinstall.packages("tm")
install.packages("tm")
install.packages("C:/Users/jailton/Downloads/tm_0.7-7.zip", repos = NULL, type = "win.binary")
library(tools, lib.loc = "C:/Program Files/R/R-3.6.1/library")
library(tm)
install.packages("C:/Users/jailton/Downloads/tm_0.7-7.zip", repos = NULL, type = "win.binary")
corpus = VCorpus(DirSource("C:/dataScience/Curso/MineracaoTextos/Dados", encoding = "UTF-8"),readerControl = list(reader=readPlain,language = "por"))
View(corpus)
getSources()
getReadres()
getReaders()
inspect(corpus)
meta(corpus[[1]])
meta(corpus[[1]])
inspect(corpus[[2]])
as.character(corpus[[2]])
stopwords("portuguese")
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus , stripWhitespace)
corpus  <- tm_map(corpus , removePunctuation)
corpus  <- tm_map(corpus , removeNumbers)
install.packages("wordcloud")
library(wordcloud)
corpus = tm_map(corpus, stemDocument,language = "english")
corpus = tm_map(corpus, stemCompletion, dictionary=corpus)
wordcloud(corpus,max.words=100,random.order=T,colors=rainbow(8),rot.per=0.5,use.r.layout=T)
freq <- TermDocumentMatrix(corpus)
matriz <- as.matrix(freq)
matriz <- sort(rowSums(matriz),decreasing=TRUE)
matriz = data.frame(word=names(matriz), freq=matriz)
wordcloud(matriz,max.words=100,random.order=T,colors=rainbow(8),rot.per=0.5,use.r.layout=T)
head(matriz, n=100)
wordcloud(matriz,max.words=100,random.order=T,colors=rainbow(8),rot.per=0.5,use.r.layout=T)
findFreqTerms(freq,500,Inf)
removeSparseTerms(freq, 0.4)
corpusSR = VCorpus(DirSource("C:/UFPE/20192/SystematicReview/ResultSelected", encoding = "UTF-8"),readerControl = list(reader=readPlain,language = "por"))
inspect(corpusSR)
corpusSR = VCorpus(DirSource("C:/UFPE/20192/SystematicReview/ResultSelected", encoding = "UTF-8"),readerControl = list(reader=readPlain,language = "por"))
inspect(corpusSR)
meta(corpus[[1]])
corpusSR = tm_map(corpusSR, removeWords, stopwords("english"))
corpusSR = tm_map(corpusSR , stripWhitespace)
corpusSR  <- tm_map(corpusSR , removePunctuation)
corpusSR  <- tm_map(corpusSR , removeNumbers)
corpusSR = tm_map(corpusSR, stemDocument,language = "english")
corpusSR = tm_map(corpusSR, stemCompletion, dictionary=corpusSR)
library(wordcloud)
wordcloud(corpusSR,max.words=100,random.order=T,colors=rainbow(8),rot.per=0.5,use.r.layout=T)
wordcloud(corpusSR,max.words=50,random.order=T,colors=rainbow(8),rot.per=0.5,use.r.layout=T)
wordcloud(corpusSR,max.words=30,random.order=T,colors=rainbow(8),rot.per=0.5,use.r.layout=T)
freq <- TermDocumentMatrix(corpusSR)
matriz <- as.matrix(freq)
matriz <- sort(rowSums(matriz),decreasing=TRUE)
matriz = data.frame(word=names(matriz), freq=matriz)
head(matriz, n=100)
wordcloud(matriz,max.words=100,random.order=T,colors=rainbow(8),rot.per=0.5,use.r.layout=T)
freq <- TermDocumentMatrix(corpusSR)
matriz <- as.matrix(freq)
matriz <- sort(rowSums(matriz),decreasing=TRUE)
matriz = data.frame(word=names(matriz), freq=matriz)
head(matriz, n=100)
getSources()
getReaders()
corpusSR = VCorpus(DirSource("C:/UFPE/20192/SystematicReview/ResultSelected", encoding = "UTF-8"),readerControl = list(reader=readPDF,language = "eng"))
install.packages('pdftools')
corpusSR = VCorpus(DirSource("C:/UFPE/20192/SystematicReview/ResultSelected", encoding = "UTF-8"),readerControl = list(reader=readPDF,language = "eng"))
inspect(corpusSR)
stopwords("english")
corpusSR = tm_map(corpusSR, removeWords, stopwords("english"))
corpusSR = tm_map(corpusSR , stripWhitespace)
corpusSR  <- tm_map(corpusSR , removePunctuation)
corpusSR  <- tm_map(corpusSR , removeNumbers)
corpusSR = tm_map(corpusSR, stemDocument,language = "english")
corpusSR = tm_map(corpusSR, stemCompletion, dictionary=corpusSR)
library(wordcloud)
wordcloud(corpusSR,max.words=30,random.order=T,colors=rainbow(8),rot.per=0.5,use.r.layout=T)
wordcloud(corpusSR,max.words=100,random.order=T,colors=rainbow(8),rot.per=0.5,use.r.layout=T)
freq <- TermDocumentMatrix(corpusSR)
matriz <- as.matrix(freq)
matriz <- sort(rowSums(matriz),decreasing=TRUE)
matriz = data.frame(word=names(matriz), freq=matriz)
head(matriz, n=100)
wordcloud(matriz,max.words=100,random.order=T,colors=rainbow(8),rot.per=0.8,use.r.layout=T)
wordcloud(matriz,max.words=100,random.order=T,colors=rainbow(8),rot.per=0.8,use.r.layout=T)
wordcloud(corpusSR,max.words=100,random.order=T,colors=rainbow(8),rot.per=0.8,use.r.layout=T)
findFreqTerms(freq,1000,Inf)
removeSparseTerms(freq, 0.4)
corpusSR = VCorpus(DirSource("C:/UFPE/20192/SystematicReview/ResultSelected", encoding = "UTF-8"),readerControl = list(reader=readPDF,language = "eng"))
as.character(corpusSR[[2]])
stopwords("english")
corpusSR = tm_map(corpusSR, removeWords,
c(stopwords("english"),"the","can","will","this","use",
"new","one","for","may","\024\005\b","fig"))
corpusSR = tm_map(corpusSR , stripWhitespace)
corpusSR  <- tm_map(corpusSR , removePunctuation)
corpusSR  <- tm_map(corpusSR , removeNumbers)
corpusSR = tm_map(corpusSR, stemDocument,language = "english")
corpusSR = tm_map(corpusSR, stemDocument,language = "english")
library(wordcloud)
wordcloud(corpusSR,max.words=100,random.order=T,colors=rainbow(8),rot.per=0.8,use.r.layout=T)
wordcloud(corpusSR,max.words=80,random.order=T,colors=rainbow(8),rot.per=0.8,use.r.layout=T)
corpusSR = tm_map(corpusSR, removeWords,
c(stopwords("english"),"the","can","will","this","use"
,"new","one","for","may","\024\005\b","fig"
,"figure","also","ieee"))
corpusSR = tm_map(corpusSR , stripWhitespace)
corpusSR  <- tm_map(corpusSR , removePunctuation)
corpusSR  <- tm_map(corpusSR , removeNumbers)
corpusSR = tm_map(corpusSR, stemDocument,language = "english")
install.packages('SnowballC')
corpusSR = tm_map(corpusSR, stemDocument,language = "english")
corpusSR = tm_map(corpusSR, stemCompletion, dictionary=corpusSR)
wordcloud(corpusSR,max.words=80,random.order=T,colors=rainbow(8),rot.per=0.8,use.r.layout=T)
corpusSR = tm_map(corpusSR, removeWords, stopwords("english"))
corpusSR = tm_map(corpusSR, removeWords, stopwords("english"))
corpusSR = tm_map(corpusSR, removeWords,
c(stopwords("english"),"the","can","will","this","use"
,"new","one","for","may","\024\005\b","fig"
,"figure","also","ieee","author","allow"
,"key","generat","differ","includ"))
corpusSR = tm_map(corpusSR , stripWhitespace)
# Remover pontuacao
corpusSR  <- tm_map(corpusSR , removePunctuation)
# Remover numeros
corpusSR  <- tm_map(corpusSR , removeNumbers)
corpusSR = tm_map(corpusSR, stemCompletion, dictionary=corpusSR)
corpusSR = tm_map(corpusSR, stemDocument,language = "english")
library(wordcloud)
wordcloud(corpusSR,max.words=80,random.order=T,colors=rainbow(8),rot.per=0.8,use.r.layout=T)
freq <- TermDocumentMatrix(corpusSR)
matriz <- as.matrix(freq)
matriz <- sort(rowSums(matriz),decreasing=TRUE)
matriz = data.frame(word=names(matriz), freq=matriz)
head(matriz, n=100)
head(matriz, n=80)
wordcloud(corpusSR,max.words=50,random.order=T,colors=rainbow(8),rot.per=0.8,use.r.layout=T)
wordcloud(corpusSR,max.words=10,random.order=T,colors=rainbow(8),rot.per=0.8,use.r.layout=T)
head(matriz, n=10)
corpusSR = tm_map(corpusSR, removeWords, stopwords("english"))
corpusSR = tm_map(corpusSR, removeWords,
c(stopwords("english"),"the","The","can","will","this","use"
,"new","one","for","may","\024\005\b","fig"
,"figure","also","ieee","author","allow"
,"key","generat","differ","includ"))
wordcloud(corpusSR,max.words=10,random.order=T,colors=rainbow(8),rot.per=0.8,use.r.layout=T)
freq <- TermDocumentMatrix(corpusSR)
matriz <- as.matrix(freq)
matriz <- sort(rowSums(matriz),decreasing=TRUE)
matriz = data.frame(word=names(matriz), freq=matriz)
head(matriz, n=10)
head(matriz, n=20)
wordcloud(corpusSR,max.words=20,random.order=T,colors=rainbow(8),rot.per=0.8,use.r.layout=T)
wordcloud(corpusSR,max.words=30,random.order=T,colors=rainbow(8),rot.per=0.8,use.r.layout=T)
head(matriz, n=40)
head(matriz, n=60)
head(matriz, n=200)
head(matriz, n=300)
head(matriz, n=500)
getSources()
getReaders()
corpusSR = VCorpus(DirSource("C:/UFPE/20192/SystematicReview/ResultSelected", encoding = "", ignore.case = FALSE),readerControl = list(reader=readPDF,language = "eng"))
as.character(corpusSR[[2]])
as.character(corpusSR[[2]])[1]
stopwords("english")
corpusSR = tm_map(corpusSR, removeWords, stopwords("english"))
corpusSR = tm_map(corpusSR, removeWords,
c(stopwords("english"),"the","The","can","will","this","use"
,"new","one","for","may","\024\005\b","fig"
,"figure","also","ieee","author","allow"
,"key","generat","differ","includ"))
corpusSR = tm_map(corpusSR , stripWhitespace)
# Remover pontuacao
corpusSR  <- tm_map(corpusSR , removePunctuation)
# Remover numeros
corpusSR  <- tm_map(corpusSR , removeNumbers)
corpusSR = tm_map(corpusSR, stemCompletion, dictionary=corpusSR)
corpusSR = tm_map(corpusSR, stemCompletion, dictionary=corpusSR)
library(wordcloud)
wordcloud(corpusSR,max.words=30,random.order=T,colors=rainbow(8),rot.per=0.8,use.r.layout=T)
freq <- TermDocumentMatrix(corpusSR)
matriz <- as.matrix(freq)
matriz <- sort(rowSums(matriz),decreasing=TRUE)
matriz = data.frame(word=names(matriz), freq=matriz)
head(matriz, n=500)
wordcloud(corpusSR,max.words=50,random.order=T,colors=rainbow(8),rot.per=0.8,use.r.layout=T)
corpusSR = tm_map(corpusSR, removeWords, stopwords("english"))
corpusSR = tm_map(corpusSR, removeWords,
c(stopwords("english"),"the","The","can","will","this","use"
,"new","one","for","may","\024\005\b","fig"
,"figure","also","ieee","author","allow"
,"key","generat","differ","includ"))
corpusSR = tm_map(corpusSR , stripWhitespace)
# Remover pontuacao
corpusSR  <- tm_map(corpusSR , removePunctuation)
# Remover numeros
corpusSR  <- tm_map(corpusSR , removeNumbers)
library(wordcloud)
wordcloud(corpusSR,max.words=40,random.order=T,colors=rainbow(8),rot.per=0.8,use.r.layout=T)
inspect(corpusSR)
inspect(corpus[2:100])
inspect(corpus[2:100])
inspect(corpusSR[[2]])
install.packages("el071", dependencies = T)
install.packages("el071", dependencies = T)
cls
install.packages("el071", dependencies = T)
install.packages("el071", dependencies = T)
library(class)
install.packages("FSelector")
library(FSelector )
install.packages("class")
install.packages("class", dependencies=T)
library(class)
head(iris)
summary(iris)
amostra = sample(2,150,replace=T, prob=c(0.7,0.3))
iristreino = iris[amostra==1,]
classificar = iris[amostra==2,]
dim(iristreino)
dim(classificar)
dim(iris)
previsao = knn(iristreino[,1:4],classificar[,1:4],iristreino[,5],k=3)
table(classificar[,5],previsao)
(tabela[1] + tabela[5] + tabela[9]) / sum(tabela)
table(classificar[,5],previsao)
(tabela[1] + tabela[5] + tabela[9]) / sum(tabela)
(table[1] + table[5] + table[9]) / sum(table)
(tabela[1] + tabela[5] + tabela[9]) / sum(tabela)
tabela = table(classificar[,5],previsao)
(tabela[1] + tabela[5] + tabela[9]) / sum(tabela)
iristreino = iris[amostra==1,]
iristreino
classificar = iris[amostra==2,]
classificar
iristreino = iris[amostra==1,]
dim(iristreino)
classificar = iris[amostra==2,]
dim(classificar)
amostra = sample(2,150,replace=T, prob=c(0.7,0.3))
iristreino = iris[amostra==1,]
classificar = iris[amostra==2,]
dim(iristreino)
dim(classificar)
previsao = knn(iristreino[,1:4],classificar[,1:4],iristreino[,5],k=3)
previsao
# Buscar o vizinho mais próximo
# Iristreino é onde vai buscar o vizinho mais próximo
# Classificar
previsao = knn(iristreino[,1:4],classificar[,1:4],iristreino[,5],k=3)
install.packages('randomForest',dependencies=T)
library(randomForest)
credito = read.csv(file.choose(),sep=',',header=T)
head(credito)
amostra = sample(2,1000,replace=T, prob=c(0.7,0.3))
creditotreino = credito[amostra==1,]
creditoteste = creditos[amostra==2,]
amostra = sample(2,1000,replace=T, prob=c(0.7,0.3))
creditotreino = credito[amostra==1,]
creditoteste = creditos[amostra==2,]
creditoteste = credito[amostra==2,]
floresta = randomForest(class ~ .,data=creditotreino, ntree=100,importance=T)
floresta = randomForest(class ~ .,data=creditotreino, ntree=100,importance=T)
floresta = randomForest(class ~.,)
floresta = randomForest(class ~., data = creditotreino)
floresta = randomForest(class ~., data = creditotreino, ntree=100)
creditotreino
creditoteste
creditoteste
creditotreino
head(creditoteste)
head(creditotreino)
dim(creditoteste)
dim(creditotreino)
install.packages('randomForest',dependencies=T)
install.packages("randomForest", dependencies = T)
library(randomForest)
floresta = randomForest(class ~ .,data=creditotreino, ntree=100,importance=T)
floresta = randomForest(class ~., data = creditotreino, ntree=100)
amostra
dim(creditoteste)
dim(creditotreino)
creditoteste
amostra
varImpPlot(floresta)
floresta = randomForest(class ~ .,data=creditotreino, ntree=100,importance=T)
floresta = randomForest(class ~ .,data=creditotreino, ntree=100,importance=T)
creditotreino
View(creditoteste)
floresta = randomForest(class ~ .,data=creditotreino, ntree=100,importance=True)
y
yes
floresta = randomForest(class ~ .,data=creditotreino, ntree=100,importance=True)
random.forest.importance(class~.,credito)
library(FSelector )
install.packages("FSelector", dependencies=T)
library(FSelector )
library(FSelector)
